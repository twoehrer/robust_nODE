{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from plots.gifs import trajectory_gif\n",
    "from plots.plots import get_feature_history, plt_train_error, plt_norm_state, plt_norm_control, plt_classifier, feature_plot, plt_dataset\n",
    "from models.training import Trainer, robTrainer\n",
    "from models.neural_odes import NeuralODE, robNeuralODE\n",
    "from models.resnets import ResNet\n",
    "import pickle\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "\n",
    "from sklearn.datasets import make_moons, make_circles\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#if trainin false, models will be loaded from file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim, data_dim = 2, 2\n",
    "T, num_steps = 5.0, 10  #T is the end time, num_steps are the amount of discretization steps for the ODE solver\n",
    "dt = T/num_steps\n",
    "turnpike = True\n",
    "bound = 0.\n",
    "fp = False\n",
    "cross_entropy = True\n",
    "\n",
    "\n",
    "training = False\n",
    "num_epochs = 50 #number of optimization epochs for gradient decent\n",
    "\n",
    "if turnpike:\n",
    "    weight_decay = 0 if bound>0. else dt*0.01\n",
    "else: \n",
    "    weight_decay = dt*0.01          #0.01 for fp, 0.1 else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "anode = NeuralODE(device, data_dim, hidden_dim, augment_dim=0, non_linearity='tanh', \n",
    "                    architecture='outside', T=T, time_steps=num_steps, fixed_projector=fp, cross_entropy=cross_entropy)\n",
    "\n",
    "optimizer_anode = torch.optim.Adam(anode.parameters(), lr=1e-3, weight_decay=weight_decay) #weight decay parameter modifies norm\n",
    "trainer_anode = Trainer(anode, optimizer_anode, device, cross_entropy=cross_entropy, \n",
    "                        turnpike=turnpike, bound=bound, fixed_projector=fp, verbose = False)\n",
    "\n",
    "\n",
    "anode_test = NeuralODE(device, data_dim, hidden_dim, augment_dim=0, non_linearity='tanh', \n",
    "                    architecture='outside', T=T, time_steps=num_steps, fixed_projector=fp, cross_entropy=cross_entropy)\n",
    "\n",
    "optimizer_anode_test = torch.optim.Adam(anode_test.parameters(), lr=1e-3, weight_decay=weight_decay) #weight decay parameter modifies norm\n",
    "trainer_anode_test = Trainer(anode_test, optimizer_anode_test, device, cross_entropy=cross_entropy, \n",
    "                        turnpike=turnpike, bound=bound, fixed_projector=fp, verbose = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rob_node = robNeuralODE(device, data_dim, hidden_dim, augment_dim=0, non_linearity='tanh', \n",
    "                            architecture='outside', T=T, time_steps=num_steps, fixed_projector=fp, cross_entropy=cross_entropy)\n",
    "\n",
    "\n",
    "optimizer_rob_node = torch.optim.Adam(rob_node.parameters(), lr=1e-3, weight_decay=weight_decay) #weight decay parameter modifies norm\n",
    "trainer_rob_node = robTrainer(rob_node, optimizer_rob_node, device, cross_entropy=cross_entropy, \n",
    "                        turnpike=turnpike, bound=bound, fixed_projector=fp, verbose = False)\n",
    "\n",
    "\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initializing self.adjoint_flow creates additional layers into rob_node. Does this effect the learning? Or can I just save/load only the important ones and it will be fine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "2400\n"
     ]
    }
   ],
   "source": [
    "#old source for data points\n",
    "with open('data.txt', 'rb') as fp:\n",
    "   data_line, test = pickle.load(fp)\n",
    "\n",
    "print(len(test))\n",
    "print(len(data_line))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Train or load the models'''\n",
    "\n",
    "#%%capture #this surpresses output\n",
    "shuffle = False\n",
    "\n",
    "\n",
    "#old source for data points\n",
    "#with open('data.txt', 'rb') as fp:\n",
    " #   data_line, test = pickle.load(fp)\n",
    "\n",
    "\n",
    "\n",
    "X, y = make_circles(3000, noise=0.3, factor=0.1, random_state=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)\n",
    "\n",
    "X_train = torch.Tensor(X_train) # transform to torch tensor for dataloader\n",
    "y_train = torch.Tensor(y_train) #transform to torch tensor for dataloader\n",
    "\n",
    "X_test = torch.Tensor(X_train) # transform to torch tensor for dataloader\n",
    "y_test = torch.Tensor(y_train) #transform to torch tensor for dataloader\n",
    "\n",
    "X_train = X_train.type(torch.float32)  #type of orginial pickle.load data\n",
    "y_train = y_train.type(torch.int64) #dtype of original picle.load data\n",
    "\n",
    "X_test = X_test.type(torch.float32)  #type of orginial pickle.load data\n",
    "y_test = y_test.type(torch.int64) #dtype of original picle.load data\n",
    "\n",
    "\n",
    "data_line = TensorDataset(X_train,y_train) # create your datset\n",
    "test = TensorDataset(X_test, y_test)\n",
    "\n",
    "dataloader = DataLoader(data_line, batch_size=64, shuffle=shuffle)\n",
    "dataloader_viz = DataLoader(data_line, batch_size=128, shuffle=shuffle)\n",
    "\n",
    "\n",
    "if training:\n",
    "    trainer_anode.train(dataloader, num_epochs)\n",
    "    trainer_anode_test.train(dataloader, num_epochs)\n",
    "\n",
    "    trainer_rob_node.train(dataloader, num_epochs)\n",
    "\n",
    "    torch.save(anode.state_dict(), 'anode.pth')\n",
    "    torch.save(rob_node.state_dict(), 'rob_node.pth')\n",
    "else:\n",
    "    anode.load_state_dict(torch.load('anode.pth'))\n",
    "    rob_node.load_state_dict(torch.load('rob_node.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "robNeuralODE(\n",
      "  (f_dynamics): Dynamics(\n",
      "    (non_linearity): Tanh()\n",
      "    (fc2_time): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "      (1): Linear(in_features=2, out_features=2, bias=True)\n",
      "      (2): Linear(in_features=2, out_features=2, bias=True)\n",
      "      (3): Linear(in_features=2, out_features=2, bias=True)\n",
      "      (4): Linear(in_features=2, out_features=2, bias=True)\n",
      "      (5): Linear(in_features=2, out_features=2, bias=True)\n",
      "      (6): Linear(in_features=2, out_features=2, bias=True)\n",
      "      (7): Linear(in_features=2, out_features=2, bias=True)\n",
      "      (8): Linear(in_features=2, out_features=2, bias=True)\n",
      "      (9): Linear(in_features=2, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (flow): Semiflow(\n",
      "    (dynamics): Dynamics(\n",
      "      (non_linearity): Tanh()\n",
      "      (fc2_time): Sequential(\n",
      "        (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "        (1): Linear(in_features=2, out_features=2, bias=True)\n",
      "        (2): Linear(in_features=2, out_features=2, bias=True)\n",
      "        (3): Linear(in_features=2, out_features=2, bias=True)\n",
      "        (4): Linear(in_features=2, out_features=2, bias=True)\n",
      "        (5): Linear(in_features=2, out_features=2, bias=True)\n",
      "        (6): Linear(in_features=2, out_features=2, bias=True)\n",
      "        (7): Linear(in_features=2, out_features=2, bias=True)\n",
      "        (8): Linear(in_features=2, out_features=2, bias=True)\n",
      "        (9): Linear(in_features=2, out_features=2, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (linear_layer): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (non_linearity): Tanh()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(rob_node)\n",
    "# print(anode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 6.6075, -6.6659])\n"
     ]
    }
   ],
   "source": [
    "filename_base = '1traj'\n",
    "\n",
    "filename_s = filename_base + '_s'\n",
    "filename_r = filename_base + '_r'\n",
    "\n",
    "plt_classifier(anode, data_line, test, num_steps=10, save_fig = '1generalization.pdf') \n",
    "plt_classifier(rob_node, data_line, test, num_steps=10, save_fig = '1rob_generalization.pdf') \n",
    "\n",
    "\n",
    "# plt.figure(1)\n",
    "# plt.subplot(121)\n",
    "# plt.imshow(imageio.imread('1generalization.png'))\n",
    "# plt.title('standard')\n",
    "# plt.axis('off')\n",
    "# plt.subplot(122)\n",
    "# plt.imshow(imageio.imread(filename_r + '29.png'))\n",
    "# plt.title('augmented robustness')\n",
    "# plt.axis('off')\n",
    "\n",
    "inputs, targets = next(iter(dataloader_viz))\n",
    "print(sum(inputs))\n",
    "\n",
    "\n",
    "\n",
    "# trajectory_gif(anode, inputs, targets, timesteps=num_steps, filename = filename_s +'.gif')\n",
    "# trajectory_gif(rob_node, inputs, targets, timesteps=num_steps, filename = filename_r + '.gif')\n",
    "filename_base = '1traj'\n",
    "\n",
    "\n",
    "# plt.figure(1)\n",
    "# plt.subplot(121)\n",
    "# plt.imshow(imageio.imread(filename_s + '29.png'))\n",
    "# plt.title('standard')\n",
    "# plt.axis('off')\n",
    "# plt.subplot(122)\n",
    "# plt.imshow(imageio.imread(filename_r + '29.png'))\n",
    "# plt.title('augmented robustness')\n",
    "# plt.axis('off')\n",
    "\n",
    "# plt.savefig('1comparison_' + filename_base + '.png',\n",
    "#                     format='png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# from IPython.display import Image\n",
    "# Image(filename='1comparison_1traj.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.state_dict of robNeuralODE(\n",
      "  (f_dynamics): Dynamics(\n",
      "    (non_linearity): Tanh()\n",
      "    (fc2_time): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "      (1): Linear(in_features=2, out_features=2, bias=True)\n",
      "      (2): Linear(in_features=2, out_features=2, bias=True)\n",
      "      (3): Linear(in_features=2, out_features=2, bias=True)\n",
      "      (4): Linear(in_features=2, out_features=2, bias=True)\n",
      "      (5): Linear(in_features=2, out_features=2, bias=True)\n",
      "      (6): Linear(in_features=2, out_features=2, bias=True)\n",
      "      (7): Linear(in_features=2, out_features=2, bias=True)\n",
      "      (8): Linear(in_features=2, out_features=2, bias=True)\n",
      "      (9): Linear(in_features=2, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (flow): Semiflow(\n",
      "    (dynamics): Dynamics(\n",
      "      (non_linearity): Tanh()\n",
      "      (fc2_time): Sequential(\n",
      "        (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "        (1): Linear(in_features=2, out_features=2, bias=True)\n",
      "        (2): Linear(in_features=2, out_features=2, bias=True)\n",
      "        (3): Linear(in_features=2, out_features=2, bias=True)\n",
      "        (4): Linear(in_features=2, out_features=2, bias=True)\n",
      "        (5): Linear(in_features=2, out_features=2, bias=True)\n",
      "        (6): Linear(in_features=2, out_features=2, bias=True)\n",
      "        (7): Linear(in_features=2, out_features=2, bias=True)\n",
      "        (8): Linear(in_features=2, out_features=2, bias=True)\n",
      "        (9): Linear(in_features=2, out_features=2, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (linear_layer): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (non_linearity): Tanh()\n",
      ")>\n",
      "anode\n",
      "flow.dynamics.fc2_time.0.weight tensor([[ 0.1466, -0.2431],\n",
      "        [ 2.2548,  1.8380]])\n",
      "flow.dynamics.fc2_time.0.bias tensor([ 0.9243, -1.3535])\n",
      "flow.dynamics.fc2_time.1.weight tensor([[ 0.8509, -0.8144],\n",
      "        [-2.4578, -0.1367]])\n",
      "flow.dynamics.fc2_time.1.bias tensor([-1.0874, -0.1209])\n",
      "flow.dynamics.fc2_time.2.weight tensor([[0.2586, 0.2352],\n",
      "        [0.0352, 0.1068]])\n",
      "flow.dynamics.fc2_time.2.bias tensor([0.9289, 1.3488])\n",
      "flow.dynamics.fc2_time.3.weight tensor([[-1.3345, -2.3286],\n",
      "        [-2.1537, -1.6655]])\n",
      "flow.dynamics.fc2_time.3.bias tensor([-0.9675, -0.3417])\n",
      "flow.dynamics.fc2_time.4.weight tensor([[0.6637, 0.5254],\n",
      "        [0.8040, 0.6890]])\n",
      "flow.dynamics.fc2_time.4.bias tensor([0.8216, 0.7410])\n",
      "flow.dynamics.fc2_time.5.weight tensor([[-1.2247,  1.8102],\n",
      "        [-0.9010,  2.3255]])\n",
      "flow.dynamics.fc2_time.5.bias tensor([-0.2597, -0.1256])\n",
      "flow.dynamics.fc2_time.6.weight tensor([[ 0.5677,  1.2628],\n",
      "        [ 1.6050, -0.2538]])\n",
      "flow.dynamics.fc2_time.6.bias tensor([ 0.1518, -0.9106])\n",
      "flow.dynamics.fc2_time.7.weight tensor([[1.9396, 0.5894],\n",
      "        [1.8209, 0.5415]])\n",
      "flow.dynamics.fc2_time.7.bias tensor([0.6190, 0.6270])\n",
      "flow.dynamics.fc2_time.8.weight tensor([[1.3206, 0.3894],\n",
      "        [0.8709, 0.3876]])\n",
      "flow.dynamics.fc2_time.8.bias tensor([0.3661, 0.4548])\n",
      "flow.dynamics.fc2_time.9.weight tensor([[0.9405, 0.2540],\n",
      "        [1.1517, 0.1680]])\n",
      "flow.dynamics.fc2_time.9.bias tensor([0.3272, 0.2310])\n",
      "linear_layer.weight tensor([[ 0.7163,  0.2312],\n",
      "        [-0.6858, -1.3599]])\n",
      "linear_layer.bias tensor([-0.2102, -0.3503])\n",
      "\n",
      " anode_test\n",
      "flow.dynamics.fc2_time.0.weight tensor([[ 0.3355, -0.6565],\n",
      "        [-0.3005,  0.5529]])\n",
      "flow.dynamics.fc2_time.0.bias tensor([0.5723, 0.6728])\n",
      "flow.dynamics.fc2_time.1.weight tensor([[ 0.1490, -0.5278],\n",
      "        [ 0.0141, -0.6677]])\n",
      "flow.dynamics.fc2_time.1.bias tensor([ 0.1180, -0.1299])\n",
      "flow.dynamics.fc2_time.2.weight tensor([[ 0.4779,  0.3728],\n",
      "        [-0.1783, -0.6854]])\n",
      "flow.dynamics.fc2_time.2.bias tensor([ 0.5098, -0.4735])\n",
      "flow.dynamics.fc2_time.3.weight tensor([[ 0.1007,  0.4041],\n",
      "        [-0.2402, -0.3491]])\n",
      "flow.dynamics.fc2_time.3.bias tensor([-0.1008,  0.3759])\n",
      "flow.dynamics.fc2_time.4.weight tensor([[0.1749, 0.6839],\n",
      "        [0.5790, 0.6962]])\n",
      "flow.dynamics.fc2_time.4.bias tensor([-0.5084,  0.6622])\n",
      "flow.dynamics.fc2_time.5.weight tensor([[ 0.0078, -0.5178],\n",
      "        [-0.3781, -0.0063]])\n",
      "flow.dynamics.fc2_time.5.bias tensor([-0.4774,  0.3125])\n",
      "flow.dynamics.fc2_time.6.weight tensor([[-0.5672,  0.0268],\n",
      "        [-0.2486,  0.3678]])\n",
      "flow.dynamics.fc2_time.6.bias tensor([ 0.6603, -0.3495])\n",
      "flow.dynamics.fc2_time.7.weight tensor([[-0.4279, -0.0256],\n",
      "        [ 0.0624,  0.4869]])\n",
      "flow.dynamics.fc2_time.7.bias tensor([ 0.4950, -0.4988])\n",
      "flow.dynamics.fc2_time.8.weight tensor([[-0.4925, -0.0525],\n",
      "        [-0.6738, -0.3351]])\n",
      "flow.dynamics.fc2_time.8.bias tensor([-0.3836,  0.1616])\n",
      "flow.dynamics.fc2_time.9.weight tensor([[ 0.1180, -0.6781],\n",
      "        [ 0.5832,  0.1714]])\n",
      "flow.dynamics.fc2_time.9.bias tensor([-0.2725,  0.4759])\n",
      "linear_layer.weight tensor([[-0.3610, -0.3678],\n",
      "        [ 0.1233, -0.2206]])\n",
      "linear_layer.bias tensor([ 0.3020, -0.1649])\n",
      "\n",
      " rob_node\n",
      "f_dynamics.fc2_time.0.weight tensor([[-1.0385,  1.9757],\n",
      "        [ 1.2917, -0.7931]])\n",
      "f_dynamics.fc2_time.0.bias tensor([ 0.9720, -0.4983])\n",
      "f_dynamics.fc2_time.1.weight tensor([[0.9467, 0.6261],\n",
      "        [0.0252, 0.0104]])\n",
      "f_dynamics.fc2_time.1.bias tensor([0.0138, 1.0425])\n",
      "f_dynamics.fc2_time.2.weight tensor([[-0.3862, -0.0501],\n",
      "        [ 0.8784,  0.7683]])\n",
      "f_dynamics.fc2_time.2.bias tensor([ 0.3520, -0.9539])\n",
      "f_dynamics.fc2_time.3.weight tensor([[0.8214, 1.9079],\n",
      "        [0.1138, 0.0807]])\n",
      "f_dynamics.fc2_time.3.bias tensor([0.5702, 1.0737])\n",
      "f_dynamics.fc2_time.4.weight tensor([[ 1.3214,  0.0584],\n",
      "        [-1.9331, -1.6934]])\n",
      "f_dynamics.fc2_time.4.bias tensor([0.0726, 0.1606])\n",
      "f_dynamics.fc2_time.5.weight tensor([[ 0.1765, -0.8634],\n",
      "        [-0.1318,  1.0536]])\n",
      "f_dynamics.fc2_time.5.bias tensor([-0.6495,  0.4279])\n",
      "f_dynamics.fc2_time.6.weight tensor([[ 1.4293,  0.5619],\n",
      "        [-0.2789,  1.3928]])\n",
      "f_dynamics.fc2_time.6.bias tensor([-0.3007, -0.1327])\n",
      "f_dynamics.fc2_time.7.weight tensor([[-0.3724, -1.0829],\n",
      "        [-0.3562,  1.7090]])\n",
      "f_dynamics.fc2_time.7.bias tensor([ 0.7478, -0.0544])\n",
      "f_dynamics.fc2_time.8.weight tensor([[ 0.5399,  1.0774],\n",
      "        [-0.4503, -1.3996]])\n",
      "f_dynamics.fc2_time.8.bias tensor([0.0901, 0.1707])\n",
      "f_dynamics.fc2_time.9.weight tensor([[0.6798, 0.4120],\n",
      "        [0.3174, 0.8140]])\n",
      "f_dynamics.fc2_time.9.bias tensor([-0.3538,  0.7774])\n",
      "linear_layer.weight tensor([[-0.3512,  0.8756],\n",
      "        [ 0.8447, -1.1385]])\n",
      "linear_layer.bias tensor([0.3952, 0.1258])\n"
     ]
    }
   ],
   "source": [
    "print(rob_node.state_dict)\n",
    "\n",
    "print('anode')\n",
    "\n",
    "for name, param in anode.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)\n",
    "\n",
    "\n",
    "print('\\n','anode_test')\n",
    "\n",
    "\n",
    "for name, param in anode_test.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)\n",
    "\n",
    "        \n",
    "        \n",
    "print('\\n','rob_node')\n",
    "\n",
    "\n",
    "for name, param in rob_node.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "13fb894ac7fe12cffb7d2d81d90b3f663ed89144aa737bba55d6b1944589c027"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('neuralode2': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
