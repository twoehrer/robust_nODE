{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from plots.gifs import trajectory_gif\n",
    "from plots.plots import get_feature_history, plt_train_error, plt_norm_state, plt_norm_control, plt_classifier, feature_plot, plt_dataset\n",
    "from models.training import Trainer, robTrainer\n",
    "from models.neural_odes import NeuralODE, robNeuralODE\n",
    "from models.resnets import ResNet\n",
    "import pickle\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "\n",
    "from sklearn.datasets import make_moons, make_circles\n",
    "\n",
    "#if trainin false, models will be loaded from file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim, data_dim = 2, 2\n",
    "T, num_steps = 5.0, 10  #T is the end time, num_steps are the amount of discretization steps for the ODE solver\n",
    "dt = T/num_steps\n",
    "turnpike = True\n",
    "bound = 0.\n",
    "fp = False\n",
    "cross_entropy = True\n",
    "\n",
    "\n",
    "training = True\n",
    "num_epochs = 50 #number of optimization epochs for gradient decent\n",
    "\n",
    "if turnpike:\n",
    "    weight_decay = 0 if bound>0. else dt*0.01\n",
    "else: \n",
    "    weight_decay = dt*0.01          #0.01 for fp, 0.1 else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "anode = NeuralODE(device, data_dim, hidden_dim, augment_dim=0, non_linearity='tanh', \n",
    "                    architecture='outside', T=T, time_steps=num_steps, fixed_projector=fp, cross_entropy=cross_entropy)\n",
    "\n",
    "optimizer_anode = torch.optim.Adam(anode.parameters(), lr=1e-3, weight_decay=weight_decay) #weight decay parameter modifies norm\n",
    "trainer_anode = Trainer(anode, optimizer_anode, device, cross_entropy=cross_entropy, \n",
    "                        turnpike=turnpike, bound=bound, fixed_projector=fp, verbose = False)\n",
    "\n",
    "\n",
    "anode_test = NeuralODE(device, data_dim, hidden_dim, augment_dim=0, non_linearity='tanh', \n",
    "                    architecture='outside', T=T, time_steps=num_steps, fixed_projector=fp, cross_entropy=cross_entropy)\n",
    "\n",
    "optimizer_anode_test = torch.optim.Adam(anode_test.parameters(), lr=1e-3, weight_decay=weight_decay) #weight decay parameter modifies norm\n",
    "trainer_anode_test = Trainer(anode_test, optimizer_anode_test, device, cross_entropy=cross_entropy, \n",
    "                        turnpike=turnpike, bound=bound, fixed_projector=fp, verbose = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rob_node = robNeuralODE(device, data_dim, hidden_dim, augment_dim=0, non_linearity='tanh', \n",
    "                            architecture='outside', T=T, time_steps=num_steps, fixed_projector=fp, cross_entropy=cross_entropy)\n",
    "\n",
    "\n",
    "optimizer_rob_node = torch.optim.Adam(rob_node.parameters(), lr=1e-3, weight_decay=weight_decay) #weight decay parameter modifies norm\n",
    "trainer_rob_node = robTrainer(rob_node, optimizer_rob_node, device, cross_entropy=cross_entropy, \n",
    "                        turnpike=turnpike, bound=bound, fixed_projector=fp, verbose = False)\n",
    "\n",
    "\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initializing self.adjoint_flow creates additional layers into rob_node. Does this effect the learning? Or can I just save/load only the important ones and it will be fine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make circle [[-0.07009304  0.04274777]\n",
      " [ 0.05338575 -0.10321302]\n",
      " [-0.46597138 -1.06687743]\n",
      " [-0.1997198   0.07076349]\n",
      " [ 0.25612559  0.0220578 ]\n",
      " [-0.49776571  0.76955129]\n",
      " [-0.31914906 -0.84899624]\n",
      " [-0.13219642  0.04854691]\n",
      " [-0.02322423  0.10138229]\n",
      " [-0.03102069  0.06437639]\n",
      " [ 0.03522898 -0.13973031]\n",
      " [ 0.17181003 -0.92504802]\n",
      " [ 0.14889241  0.14202291]\n",
      " [ 0.19824756 -0.04897413]\n",
      " [ 0.12498214 -0.10121185]\n",
      " [-0.47960986 -0.7880243 ]\n",
      " [-0.90187751 -0.70895455]\n",
      " [ 0.74827659 -0.55976747]\n",
      " [-0.0979097  -0.11384725]\n",
      " [ 0.23161178  1.01205842]\n",
      " [ 0.81387506  0.22821311]\n",
      " [-0.24368754  0.02902427]\n",
      " [ 0.0956608  -0.10092505]\n",
      " [-0.03065257 -0.01692678]\n",
      " [-0.72651409  0.58630948]\n",
      " [-0.33930852 -1.0080984 ]\n",
      " [-0.02017866 -0.1459128 ]\n",
      " [-0.9539309  -0.33410313]\n",
      " [ 0.6927241  -0.59576417]\n",
      " [ 0.003546   -0.9098264 ]\n",
      " [ 0.02430112  0.23433603]\n",
      " [ 0.2535024  -0.05730649]\n",
      " [-0.09013857 -0.13100816]\n",
      " [-0.01960484 -0.09881616]\n",
      " [ 0.05990489  0.0301758 ]\n",
      " [ 0.31843503 -0.97937344]\n",
      " [ 0.92901189 -0.31993308]\n",
      " [-0.09305663  0.00671114]\n",
      " [-1.01797423  0.23454524]\n",
      " [-0.51324637 -0.80013947]\n",
      " [ 0.00824558 -0.05733719]\n",
      " [ 0.05924395  0.04788713]\n",
      " [-0.03941829  0.04379403]\n",
      " [-0.13663998  0.7088594 ]\n",
      " [-0.20370098 -0.07979291]\n",
      " [ 0.41812614 -0.82061786]\n",
      " [ 0.84575703 -0.63891465]\n",
      " [-0.03096779 -0.11656792]\n",
      " [-0.87474347 -0.09886802]\n",
      " [-0.05370264  0.08091352]\n",
      " [ 0.65495356 -0.59471995]\n",
      " [ 0.00814107  0.11027544]\n",
      " [-1.0617065   0.30319732]\n",
      " [ 0.96779554  0.56332827]\n",
      " [ 0.12472429  0.0673018 ]\n",
      " [ 0.9717675  -0.08311653]\n",
      " [-0.74061828  0.46063137]\n",
      " [ 0.12599239 -0.25922455]\n",
      " [ 0.9202249   0.33757265]\n",
      " [-0.07631515 -0.0374205 ]\n",
      " [-0.8114891  -0.61756242]\n",
      " [-0.0520898   0.1169459 ]\n",
      " [-0.17745236  0.05194805]\n",
      " [ 0.63771423 -0.84351537]\n",
      " [ 0.75136154 -0.34005691]\n",
      " [ 0.09599847 -0.12657946]\n",
      " [ 0.52855241  0.89270399]\n",
      " [ 0.12351344 -0.08960859]\n",
      " [ 1.02669518 -0.01098796]\n",
      " [-0.03971522 -0.17423903]\n",
      " [ 0.02551585  0.12958333]\n",
      " [-0.9112213   0.50131608]\n",
      " [ 0.0555211  -0.02960078]\n",
      " [-0.01863995  0.04446649]\n",
      " [ 0.74218942  0.79243568]\n",
      " [ 0.01843497  0.0325479 ]\n",
      " [-0.10163336  0.86144353]\n",
      " [ 0.06820348 -0.02349034]\n",
      " [-0.07686687 -0.07375821]\n",
      " [-0.21099388  0.81161572]\n",
      " [-1.00407781 -0.55070155]\n",
      " [-0.92695735 -0.41057272]\n",
      " [ 0.20497791  0.87640661]\n",
      " [-0.66598082  0.65032736]\n",
      " [-0.92263395  0.68059245]\n",
      " [ 0.10940293  0.15076116]\n",
      " [-0.8871477   0.01276883]\n",
      " [ 0.72182595  0.62661863]\n",
      " [-0.03793037  0.16186727]\n",
      " [-0.02492902  0.08600707]\n",
      " [ 1.06096133  0.0840763 ]\n",
      " [-0.40443454  0.84799759]\n",
      " [-0.00901851 -0.03811184]\n",
      " [-0.09328001  0.04365172]\n",
      " [ 0.83342493  0.61278707]\n",
      " [-0.08743102 -0.11249056]\n",
      " [ 0.27602586  0.88730559]\n",
      " [-0.18421581 -0.23693087]\n",
      " [ 0.26859755  1.00452129]\n",
      " [-0.22422412 -0.90416928]]\n",
      "<torch.utils.data.dataset.Subset object at 0x7fc7ab820fd0>\n"
     ]
    }
   ],
   "source": [
    "X, y = make_circles(noise=0.1, factor=0.1, random_state=1)\n",
    "print('make circle', data_line)\n",
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "my_x = [np.array([[1.0,2],[3,4]]),np.array([[5.,6],[7,8]])] # a list of numpy arrays\n",
    "my_y = [np.array([4.]), np.array([2.])] # another list of numpy arrays (targets)\n",
    "\n",
    "tensor_x = torch.Tensor(my_x) # transform to torch tensor\n",
    "tensor_y = torch.Tensor(my_y)\n",
    "\n",
    "my_dataset = TensorDataset(tensor_x,tensor_y) # create your datset\n",
    "my_dataloader = DataLoader(my_dataset) # create your dataloader\n",
    "\n",
    "with open('data.txt', 'rb') as fp:\n",
    "    data_line, test = pickle.load(fp)\n",
    "    print(data_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29835/1174745747.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtrainer_anode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mtrainer_anode_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FAUbox/Python/borjan dynamical.systems/models/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_loader, num_epochs)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch {}: {:.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FAUbox/Python/borjan dynamical.systems/models/training.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, data_loader, epoch)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mepoch_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mx_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "'''Train or load the models'''\n",
    "\n",
    "#%%capture #this surpresses output\n",
    "shuffle = False\n",
    "\n",
    "#with open('data.txt', 'rb') as fp:\n",
    " #   data_line, test = pickle.load(fp)\n",
    "\n",
    "X, y = make_circles(noise=0.1, factor=0.1, random_state=1)\n",
    "\n",
    "\n",
    "dataloader = DataLoader(data_line, batch_size=64, shuffle=shuffle)\n",
    "dataloader_viz = DataLoader(data_line, batch_size=128, shuffle=shuffle)\n",
    "\n",
    "\n",
    "if training:\n",
    "    trainer_anode.train(dataloader, num_epochs)\n",
    "    trainer_anode_test.train(dataloader, num_epochs)\n",
    "\n",
    "    trainer_rob_node.train(dataloader, num_epochs)\n",
    "\n",
    "    torch.save(anode.state_dict(), 'anode.pth')\n",
    "    torch.save(rob_node.state_dict(), 'rob_node.pth')\n",
    "else:\n",
    "    anode.load_state_dict(torch.load('anode.pth'))\n",
    "    rob_node.load_state_dict(torch.load('rob_node.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "robNeuralODE(\n",
      "  (f_dynamics): Dynamics(\n",
      "    (non_linearity): Tanh()\n",
      "    (fc2_time): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "      (1): Linear(in_features=2, out_features=2, bias=True)\n",
      "      (2): Linear(in_features=2, out_features=2, bias=True)\n",
      "      (3): Linear(in_features=2, out_features=2, bias=True)\n",
      "      (4): Linear(in_features=2, out_features=2, bias=True)\n",
      "      (5): Linear(in_features=2, out_features=2, bias=True)\n",
      "      (6): Linear(in_features=2, out_features=2, bias=True)\n",
      "      (7): Linear(in_features=2, out_features=2, bias=True)\n",
      "      (8): Linear(in_features=2, out_features=2, bias=True)\n",
      "      (9): Linear(in_features=2, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (flow): Semiflow(\n",
      "    (dynamics): Dynamics(\n",
      "      (non_linearity): Tanh()\n",
      "      (fc2_time): Sequential(\n",
      "        (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "        (1): Linear(in_features=2, out_features=2, bias=True)\n",
      "        (2): Linear(in_features=2, out_features=2, bias=True)\n",
      "        (3): Linear(in_features=2, out_features=2, bias=True)\n",
      "        (4): Linear(in_features=2, out_features=2, bias=True)\n",
      "        (5): Linear(in_features=2, out_features=2, bias=True)\n",
      "        (6): Linear(in_features=2, out_features=2, bias=True)\n",
      "        (7): Linear(in_features=2, out_features=2, bias=True)\n",
      "        (8): Linear(in_features=2, out_features=2, bias=True)\n",
      "        (9): Linear(in_features=2, out_features=2, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (linear_layer): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (non_linearity): Tanh()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(rob_node)\n",
    "# print(anode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/np1/staff/woehrer/FAUbox/Python/borjan dynamical.systems/plots/plots.py:380: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  predictions = m(pre_)\n",
      "/home/np1/staff/woehrer/FAUbox/Python/borjan dynamical.systems/plots/plots.py:380: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  predictions = m(pre_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0701,  0.0427],\n",
      "        [ 0.0534, -0.1032],\n",
      "        [-0.4660, -1.0669],\n",
      "        [-0.1997,  0.0708],\n",
      "        [ 0.2561,  0.0221],\n",
      "        [-0.4978,  0.7696],\n",
      "        [-0.3191, -0.8490],\n",
      "        [-0.1322,  0.0485],\n",
      "        [-0.0232,  0.1014],\n",
      "        [-0.0310,  0.0644],\n",
      "        [ 0.0352, -0.1397],\n",
      "        [ 0.1718, -0.9250],\n",
      "        [ 0.1489,  0.1420],\n",
      "        [ 0.1982, -0.0490],\n",
      "        [ 0.1250, -0.1012],\n",
      "        [-0.4796, -0.7880],\n",
      "        [-0.9019, -0.7090],\n",
      "        [ 0.7483, -0.5598],\n",
      "        [-0.0979, -0.1138],\n",
      "        [ 0.2316,  1.0121],\n",
      "        [ 0.8139,  0.2282],\n",
      "        [-0.2437,  0.0290],\n",
      "        [ 0.0957, -0.1009],\n",
      "        [-0.0307, -0.0169],\n",
      "        [-0.7265,  0.5863],\n",
      "        [-0.3393, -1.0081],\n",
      "        [-0.0202, -0.1459],\n",
      "        [-0.9539, -0.3341],\n",
      "        [ 0.6927, -0.5958],\n",
      "        [ 0.0035, -0.9098],\n",
      "        [ 0.0243,  0.2343],\n",
      "        [ 0.2535, -0.0573],\n",
      "        [-0.0901, -0.1310],\n",
      "        [-0.0196, -0.0988],\n",
      "        [ 0.0599,  0.0302],\n",
      "        [ 0.3184, -0.9794],\n",
      "        [ 0.9290, -0.3199],\n",
      "        [-0.0931,  0.0067],\n",
      "        [-1.0180,  0.2345],\n",
      "        [-0.5132, -0.8001],\n",
      "        [ 0.0082, -0.0573],\n",
      "        [ 0.0592,  0.0479],\n",
      "        [-0.0394,  0.0438],\n",
      "        [-0.1366,  0.7089],\n",
      "        [-0.2037, -0.0798],\n",
      "        [ 0.4181, -0.8206],\n",
      "        [ 0.8458, -0.6389],\n",
      "        [-0.0310, -0.1166],\n",
      "        [-0.8747, -0.0989],\n",
      "        [-0.0537,  0.0809],\n",
      "        [ 0.6550, -0.5947],\n",
      "        [ 0.0081,  0.1103],\n",
      "        [-1.0617,  0.3032],\n",
      "        [ 0.9678,  0.5633],\n",
      "        [ 0.1247,  0.0673],\n",
      "        [ 0.9718, -0.0831],\n",
      "        [-0.7406,  0.4606],\n",
      "        [ 0.1260, -0.2592],\n",
      "        [ 0.9202,  0.3376],\n",
      "        [-0.0763, -0.0374],\n",
      "        [-0.8115, -0.6176],\n",
      "        [-0.0521,  0.1169],\n",
      "        [-0.1775,  0.0519],\n",
      "        [ 0.6377, -0.8435],\n",
      "        [ 0.7514, -0.3401],\n",
      "        [ 0.0960, -0.1266],\n",
      "        [ 0.5286,  0.8927],\n",
      "        [ 0.1235, -0.0896],\n",
      "        [ 1.0267, -0.0110],\n",
      "        [-0.0397, -0.1742],\n",
      "        [ 0.0255,  0.1296],\n",
      "        [-0.9112,  0.5013],\n",
      "        [ 0.0555, -0.0296],\n",
      "        [-0.0186,  0.0445],\n",
      "        [ 0.7422,  0.7924],\n",
      "        [ 0.0184,  0.0325],\n",
      "        [-0.1016,  0.8614],\n",
      "        [ 0.0682, -0.0235],\n",
      "        [-0.0769, -0.0738],\n",
      "        [-0.2110,  0.8116],\n",
      "        [-1.0041, -0.5507],\n",
      "        [-0.9270, -0.4106],\n",
      "        [ 0.2050,  0.8764],\n",
      "        [-0.6660,  0.6503],\n",
      "        [-0.9226,  0.6806],\n",
      "        [ 0.1094,  0.1508],\n",
      "        [-0.8871,  0.0128],\n",
      "        [ 0.7218,  0.6266],\n",
      "        [-0.0379,  0.1619],\n",
      "        [-0.0249,  0.0860],\n",
      "        [ 1.0610,  0.0841],\n",
      "        [-0.4044,  0.8480],\n",
      "        [-0.0090, -0.0381],\n",
      "        [-0.0933,  0.0437],\n",
      "        [ 0.8334,  0.6128],\n",
      "        [-0.0874, -0.1125],\n",
      "        [ 0.2760,  0.8873],\n",
      "        [-0.1842, -0.2369],\n",
      "        [ 0.2686,  1.0045],\n",
      "        [-0.2242, -0.9042]], dtype=torch.float64)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_911/1984567292.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# plt_classifier(rob_node, num_steps=10, save_fig = '1rob_generalization.pdf')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtrajectory_gif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename_s\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'.gif'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mtrajectory_gif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrob_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename_r\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.gif'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FAUbox/Python/borjan dynamical.systems/plots/gifs.py\u001b[0m in \u001b[0;36mtrajectory_gif\u001b[0;34m(model, inputs, targets, timesteps, dpi, alpha, alpha_line, filename)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m## We focus on 3 colors at most\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'mediumpurple'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2.0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'gold'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'mediumseagreen'\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "filename_base = '1traj'\n",
    "filename_s = filename_base + '_s'\n",
    "filename_r = filename_base + '_r'\n",
    "\n",
    "plt_classifier(anode, num_steps=10, save_fig = '1generalization.pdf') \n",
    "plt_classifier(rob_node, num_steps=10, save_fig = '1rob_generalization.pdf') \n",
    "\n",
    "inputs, targets = next(iter(dataloader_viz))\n",
    "print(sum(inputs))\n",
    "\n",
    "\n",
    "# plt_classifier(rob_node, num_steps=10, save_fig = '1rob_generalization.pdf')\n",
    "trajectory_gif(anode, inputs, targets, timesteps=num_steps, filename = filename_s +'.gif')\n",
    "trajectory_gif(rob_node, inputs, targets, timesteps=num_steps, filename = filename_r + '.gif')\n",
    "\n",
    "# plt.figure(1)\n",
    "# plt.subplot(121)\n",
    "# plt.imshow(imageio.imread(filename_s + '29.png'))\n",
    "# plt.title('standard')\n",
    "# plt.axis('off')\n",
    "# plt.subplot(122)\n",
    "# plt.imshow(imageio.imread(filename_r + '29.png'))\n",
    "# plt.title('augmented robustness')\n",
    "# plt.axis('off')\n",
    "\n",
    "# plt.savefig('1comparison_' + filename_base + '.png',\n",
    "#                     format='png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# from IPython.display import Image\n",
    "# Image(filename='1comparison_1traj.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.state_dict of robNeuralODE(\n",
      "  (f_dynamics): Dynamics(\n",
      "    (non_linearity): Tanh()\n",
      "    (fc2_time): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "      (1): Linear(in_features=2, out_features=2, bias=True)\n",
      "      (2): Linear(in_features=2, out_features=2, bias=True)\n",
      "      (3): Linear(in_features=2, out_features=2, bias=True)\n",
      "      (4): Linear(in_features=2, out_features=2, bias=True)\n",
      "      (5): Linear(in_features=2, out_features=2, bias=True)\n",
      "      (6): Linear(in_features=2, out_features=2, bias=True)\n",
      "      (7): Linear(in_features=2, out_features=2, bias=True)\n",
      "      (8): Linear(in_features=2, out_features=2, bias=True)\n",
      "      (9): Linear(in_features=2, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (flow): Semiflow(\n",
      "    (dynamics): Dynamics(\n",
      "      (non_linearity): Tanh()\n",
      "      (fc2_time): Sequential(\n",
      "        (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "        (1): Linear(in_features=2, out_features=2, bias=True)\n",
      "        (2): Linear(in_features=2, out_features=2, bias=True)\n",
      "        (3): Linear(in_features=2, out_features=2, bias=True)\n",
      "        (4): Linear(in_features=2, out_features=2, bias=True)\n",
      "        (5): Linear(in_features=2, out_features=2, bias=True)\n",
      "        (6): Linear(in_features=2, out_features=2, bias=True)\n",
      "        (7): Linear(in_features=2, out_features=2, bias=True)\n",
      "        (8): Linear(in_features=2, out_features=2, bias=True)\n",
      "        (9): Linear(in_features=2, out_features=2, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (linear_layer): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (non_linearity): Tanh()\n",
      ")>\n",
      "anode\n",
      "flow.dynamics.fc2_time.0.weight tensor([[-0.3809,  0.1612],\n",
      "        [ 0.4220,  0.1496]])\n",
      "flow.dynamics.fc2_time.0.bias tensor([ 0.3969, -0.4876])\n",
      "flow.dynamics.fc2_time.1.weight tensor([[-1.1565,  1.6086],\n",
      "        [-0.0351,  0.1508]])\n",
      "flow.dynamics.fc2_time.1.bias tensor([-0.0288, -0.8493])\n",
      "flow.dynamics.fc2_time.2.weight tensor([[-3.6903,  2.6295],\n",
      "        [ 2.7528, -0.2159]])\n",
      "flow.dynamics.fc2_time.2.bias tensor([0.1290, 1.0816])\n",
      "flow.dynamics.fc2_time.3.weight tensor([[ 2.0431, -1.2293],\n",
      "        [-0.4201,  0.3481]])\n",
      "flow.dynamics.fc2_time.3.bias tensor([ 0.3329, -0.5419])\n",
      "flow.dynamics.fc2_time.4.weight tensor([[ 1.9889,  1.0871],\n",
      "        [-2.9184, -0.8476]])\n",
      "flow.dynamics.fc2_time.4.bias tensor([-0.2249,  0.0357])\n",
      "flow.dynamics.fc2_time.5.weight tensor([[ 1.4828, -1.4668],\n",
      "        [-1.4718,  1.8142]])\n",
      "flow.dynamics.fc2_time.5.bias tensor([ 0.5543, -0.0745])\n",
      "flow.dynamics.fc2_time.6.weight tensor([[ 1.2234, -1.3368],\n",
      "        [-1.1755,  0.9379]])\n",
      "flow.dynamics.fc2_time.6.bias tensor([ 0.2938, -0.4171])\n",
      "flow.dynamics.fc2_time.7.weight tensor([[ 0.8641, -1.3005],\n",
      "        [-0.8332,  1.1345]])\n",
      "flow.dynamics.fc2_time.7.bias tensor([ 0.3831, -0.4881])\n",
      "flow.dynamics.fc2_time.8.weight tensor([[ 0.6473, -0.8158],\n",
      "        [-0.5538,  0.8442]])\n",
      "flow.dynamics.fc2_time.8.bias tensor([ 0.3478, -0.1758])\n",
      "flow.dynamics.fc2_time.9.weight tensor([[ 0.2501, -0.4179],\n",
      "        [-0.1597,  0.2814]])\n",
      "flow.dynamics.fc2_time.9.bias tensor([ 0.0255, -0.1748])\n",
      "linear_layer.weight tensor([[-0.9230,  0.7536],\n",
      "        [ 1.0225, -0.3903]])\n",
      "linear_layer.bias tensor([0.1915, 0.8079])\n",
      "\n",
      " anode_test\n",
      "flow.dynamics.fc2_time.0.weight tensor([[-2.6887,  2.2222],\n",
      "        [ 2.1401, -3.1257]])\n",
      "flow.dynamics.fc2_time.0.bias tensor([ 1.6472, -1.8355])\n",
      "flow.dynamics.fc2_time.1.weight tensor([[ 0.0314,  0.2032],\n",
      "        [-0.0714, -0.0257]])\n",
      "flow.dynamics.fc2_time.1.bias tensor([-0.6932,  0.1833])\n",
      "flow.dynamics.fc2_time.2.weight tensor([[-0.3468,  0.6738],\n",
      "        [ 2.2611,  2.7667]])\n",
      "flow.dynamics.fc2_time.2.bias tensor([-0.3450, -1.2905])\n",
      "flow.dynamics.fc2_time.3.weight tensor([[ 0.9166, -0.3432],\n",
      "        [-0.4857,  0.3954]])\n",
      "flow.dynamics.fc2_time.3.bias tensor([0.1998, 0.3535])\n",
      "flow.dynamics.fc2_time.4.weight tensor([[-2.7090, -1.5982],\n",
      "        [-0.2804,  0.2083]])\n",
      "flow.dynamics.fc2_time.4.bias tensor([0.6394, 0.6609])\n",
      "flow.dynamics.fc2_time.5.weight tensor([[ 2.2663, -0.6710],\n",
      "        [-1.5296,  0.6147]])\n",
      "flow.dynamics.fc2_time.5.bias tensor([-0.0705,  0.4606])\n",
      "flow.dynamics.fc2_time.6.weight tensor([[ 1.6931, -1.2456],\n",
      "        [-0.4005,  0.2660]])\n",
      "flow.dynamics.fc2_time.6.bias tensor([0.0183, 0.8175])\n",
      "flow.dynamics.fc2_time.7.weight tensor([[0.5659, 2.4622],\n",
      "        [0.0978, 0.0366]])\n",
      "flow.dynamics.fc2_time.7.bias tensor([0.5064, 1.2164])\n",
      "flow.dynamics.fc2_time.8.weight tensor([[ 1.1663, -1.1129],\n",
      "        [ 0.9119, -1.2880]])\n",
      "flow.dynamics.fc2_time.8.bias tensor([-0.0578, -0.8333])\n",
      "flow.dynamics.fc2_time.9.weight tensor([[ 0.4223, -0.4219],\n",
      "        [ 0.1027,  0.1173]])\n",
      "flow.dynamics.fc2_time.9.bias tensor([-0.1424,  0.6527])\n",
      "linear_layer.weight tensor([[ 0.3153, -0.5538],\n",
      "        [-1.5466,  1.2510]])\n",
      "linear_layer.bias tensor([-0.2777,  0.8606])\n",
      "\n",
      " rob_node\n",
      "f_dynamics.fc2_time.0.weight tensor([[-0.0980, -0.3736],\n",
      "        [-0.6460, -2.4733]])\n",
      "f_dynamics.fc2_time.0.bias tensor([-0.8117,  1.0550])\n",
      "f_dynamics.fc2_time.1.weight tensor([[-0.0819, -0.8281],\n",
      "        [-2.8886, -1.8953]])\n",
      "f_dynamics.fc2_time.1.bias tensor([-0.0595,  1.0753])\n",
      "f_dynamics.fc2_time.2.weight tensor([[ 0.1432,  0.0421],\n",
      "        [-1.7774,  0.9313]])\n",
      "f_dynamics.fc2_time.2.bias tensor([-1.0496, -0.1089])\n",
      "f_dynamics.fc2_time.3.weight tensor([[ 0.4680, -0.5369],\n",
      "        [ 0.3580,  0.3917]])\n",
      "f_dynamics.fc2_time.3.bias tensor([ 1.4566, -1.3531])\n",
      "f_dynamics.fc2_time.4.weight tensor([[ 0.2915,  0.2767],\n",
      "        [-0.2175, -1.8907]])\n",
      "f_dynamics.fc2_time.4.bias tensor([-0.1206,  1.7793])\n",
      "f_dynamics.fc2_time.5.weight tensor([[0.8596, 1.0139],\n",
      "        [0.4991, 0.9055]])\n",
      "f_dynamics.fc2_time.5.bias tensor([ 0.2230, -0.5317])\n",
      "f_dynamics.fc2_time.6.weight tensor([[ 0.5673,  0.3232],\n",
      "        [-1.6530,  1.1406]])\n",
      "f_dynamics.fc2_time.6.bias tensor([ 0.0593, -0.4737])\n",
      "f_dynamics.fc2_time.7.weight tensor([[-0.9845,  1.0510],\n",
      "        [ 0.4807,  0.2596]])\n",
      "f_dynamics.fc2_time.7.bias tensor([-0.5315, -0.6783])\n",
      "f_dynamics.fc2_time.8.weight tensor([[0.9564, 1.0983],\n",
      "        [0.8441, 0.7389]])\n",
      "f_dynamics.fc2_time.8.bias tensor([-0.0502, -0.1470])\n",
      "f_dynamics.fc2_time.9.weight tensor([[-0.1170, -0.2190],\n",
      "        [ 0.6500,  1.0100]])\n",
      "f_dynamics.fc2_time.9.bias tensor([-1.1184,  0.1209])\n",
      "linear_layer.weight tensor([[ 0.7046,  1.0339],\n",
      "        [-0.5213, -1.0628]])\n",
      "linear_layer.bias tensor([-0.9621,  0.0189])\n"
     ]
    }
   ],
   "source": [
    "print(rob_node.state_dict)\n",
    "\n",
    "print('anode')\n",
    "\n",
    "for name, param in anode.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)\n",
    "\n",
    "\n",
    "print('\\n','anode_test')\n",
    "\n",
    "\n",
    "for name, param in anode_test.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)\n",
    "\n",
    "        \n",
    "        \n",
    "print('\\n','rob_node')\n",
    "\n",
    "\n",
    "for name, param in rob_node.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "13fb894ac7fe12cffb7d2d81d90b3f663ed89144aa737bba55d6b1944589c027"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('neuralode2': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
